{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "5n5Hd_tduCvN"
      },
      "outputs": [],
      "source": [
        "#Jatin Goyal\n",
        "#3CO12\n",
        "#102003307"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "sPWvVHy8LpQK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "GIRvdCQBN110"
      },
      "outputs": [],
      "source": [
        "cc=pd.read_csv(\"Creditcard_data.csv\")\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "x=cc.drop('Class',axis=1)\n",
        "y=cc['Class']\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_ros, y_ros = ros.fit_resample(x, y)\n",
        "\n",
        "\n",
        "\n",
        "# Create a new balanced dataframe\n",
        "cc_balanced= pd.concat([x_ros, y_ros], axis=1)\n",
        "\n",
        "# Save the balanced dataframe to a new CSV file\n",
        "cc_balanced.to_csv('Balanced_data.csv', index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVjToEZ7OZJs",
        "outputId": "caec207e-b3b2-4fae-a949-6e6444d84e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Time        V1        V2        V3        V4        V5        V6  \\\n",
            "1361   484 -0.928088  0.398194  1.741131  0.182673  0.966387 -0.901004   \n",
            "511    377  1.166919  0.027049  0.513875  0.860965 -0.519452 -0.681147   \n",
            "9        9 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761   \n",
            "393    284 -0.810756  0.654499  2.217257  0.104341 -0.286801  0.117833   \n",
            "471    346  1.077079  0.284980  0.007731  1.657073  0.052020  0.446389   \n",
            "...    ...       ...       ...       ...       ...       ...       ...   \n",
            "829    118  1.254914  0.350287  0.302488  0.693114 -0.371470 -1.070256   \n",
            "530    394  1.293053  0.457969 -1.940450  0.173149  2.609570  3.014117   \n",
            "1363   472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
            "795      0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
            "1370   472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
            "\n",
            "            V7        V8        V9  ...       V21       V22       V23  \\\n",
            "1361  0.879016 -0.156590 -0.142117  ...  0.066353  0.281378 -0.257966   \n",
            "511   0.074992 -0.187776  0.345399  ... -0.202750 -0.441391 -0.025782   \n",
            "9     0.651583  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794   \n",
            "393   0.287552 -0.736461  0.699092  ...  0.938194  0.571651 -0.101609   \n",
            "471  -0.407036  0.355704  0.626039  ... -0.174337 -0.174161 -0.153375   \n",
            "...        ...       ...       ...  ...       ...       ...       ...   \n",
            "829   0.086781 -0.202836  0.035154  ... -0.287592 -0.832682  0.128083   \n",
            "530  -0.269415  0.754420 -0.221009  ... -0.121126 -0.427753 -0.159336   \n",
            "1363  0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
            "795  -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
            "1370  0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
            "\n",
            "           V24       V25       V26       V27       V28  Amount  Class  \n",
            "1361  0.385384  0.391117 -0.453853 -0.104448 -0.125765    1.00      1  \n",
            "511   0.452607  0.467223  0.262577 -0.023834  0.020521   40.83      0  \n",
            "9    -0.385050 -0.069733  0.094199  0.246219  0.083076    3.68      0  \n",
            "393   0.363928 -0.170947 -0.471524  0.058958 -0.079157   30.30      0  \n",
            "471  -0.466331  0.611001 -0.252871  0.090375  0.054820   10.99      0  \n",
            "...        ...       ...       ...       ...       ...     ...    ...  \n",
            "829   0.339427  0.215944  0.094704 -0.023354  0.030892    2.69      1  \n",
            "530   0.857135  0.850055 -0.311685  0.037536  0.050618    1.00      0  \n",
            "1363 -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
            "795  -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
            "1370 -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
            "\n",
            "[384 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Creating a random sample using random sampling\n",
        "np.random.seed(0)\n",
        "\n",
        "sample_size=int((pow(1.96,2)*0.5*0.5)/0.0025)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "random_sample = cc_balanced.sample(n=sample_size, random_state=0)\n",
        "print(random_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "bM7pYwPc1dML",
        "outputId": "141829ca-d17a-4d0f-9f3d-ba75d46c0fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression accuracy: 0.8958333333333334\n",
            "Decision Tree accuracy: 0.9895833333333334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jatin\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC accuracy: 0.9270833333333334\n",
            "Random Forest accuracy: 1.0\n",
            "Naive bayes Classifier accuracy: 0.7395833333333334\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random_Sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.895833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.989583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.927083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.739583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Random_Sampling\n",
              "Logistic Regression         0.895833\n",
              "Decision Tree               0.989583\n",
              "SVC                         0.927083\n",
              "Random forest               1.000000\n",
              "Naive Bayes                 0.739583"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Now we will aplly 5 different models to our random sample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "x_random= random_sample.drop(columns=['Class'])\n",
        "y_random = random_sample['Class']\n",
        "x_random_train, x_random_test,y_random_train, y_random_test = train_test_split(x_random,y_random, random_state=132, \n",
        "                                   test_size=0.25, \n",
        "                                   shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# Train and evaluate the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "     \"SVC\" : svm.SVC(kernel='linear', C = 1.0) \n",
        "    ,\n",
        "    \"Random Forest\": RandomForestClassifier() ,\n",
        "    \"Naive bayes Classifier\":GaussianNB()\n",
        "    \n",
        "}\n",
        "acc_l=[]\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(x_random_train,y_random_train)\n",
        "    y_pred = model.predict(x_random_test)\n",
        "    acc = accuracy_score(y_random_test, y_pred)\n",
        "    print(f\"{name} accuracy: {acc}\")\n",
        "    acc_l.append(acc)\n",
        "acc_m=pd.DataFrame(acc_l,index=['Logistic Regression','Decision Tree','SVC','Random forest','Naive Bayes'])\n",
        "acc_m.rename(columns={ acc_m.columns[0]: \"Random_Sampling\" }, inplace = True)\n",
        "acc_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-MOIlOVftwO",
        "outputId": "ab731954-2788-4155-f9fb-9cfd775b038e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Time        V1        V2        V3        V4        V5        V6  \\\n",
            "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
            "39      29  1.110880  0.168717  0.517144  1.325407 -0.191573  0.019504   \n",
            "78      50 -0.571521  1.071600  1.280110  0.542780  0.574439 -0.259359   \n",
            "117     76 -1.024576  0.522289  1.787699  0.202672 -1.140803 -0.137831   \n",
            "156     98 -0.646513  1.004199  1.616224 -0.099628 -0.122477 -0.671327   \n",
            "195    128  1.239495 -0.182609  0.155058 -0.928892 -0.746227 -1.235608   \n",
            "234    156  0.714401 -0.493905  1.269485  3.011494 -0.801216  0.929404   \n",
            "273    194 -1.131517  1.016399  0.735810  1.166614  0.790236 -1.187196   \n",
            "312    225  1.478773 -0.551089 -0.523152 -0.831153 -0.195413 -0.289193   \n",
            "351    259 -1.569485 -1.932133  1.249203 -4.434211  1.244282  0.402688   \n",
            "390    284 -0.942623  0.657318  1.191544  1.326497  0.976745 -0.832970   \n",
            "429    310 -0.728857 -0.020542  1.415026  1.233902 -0.240077  0.482240   \n",
            "468    344 -3.495984 -4.088420  2.024845 -0.740363  1.128135 -1.231702   \n",
            "507    375 -0.837689  0.777698  1.841252  3.056892  0.303627  0.615335   \n",
            "546    409  1.243758 -0.777764  1.016830 -0.250546 -1.268555  0.137280   \n",
            "585    438  1.287087 -0.392364  0.513360 -1.237322 -0.402556  0.474908   \n",
            "624    472  1.040781  0.109569  0.357987  1.118998 -0.105373 -0.056837   \n",
            "663    501 -1.377718  1.354530  0.543183 -1.427171 -0.124389 -0.524309   \n",
            "702    530  1.217261 -0.080646 -0.059293 -0.868862 -0.236628 -0.700159   \n",
            "741    557  1.173585  0.250650  0.839631  1.066309 -0.365090 -0.161887   \n",
            "780    472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
            "819    406 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
            "858    529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n",
            "897    529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n",
            "936      0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
            "975    118  1.254914  0.350287  0.302488  0.693114 -0.371470 -1.070256   \n",
            "1014   574  1.257719  0.364739  0.306923  0.690638 -0.357792 -1.067481   \n",
            "1053   472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
            "1092   118  1.254914  0.350287  0.302488  0.693114 -0.371470 -1.070256   \n",
            "1131   574  1.257719  0.364739  0.306923  0.690638 -0.357792 -1.067481   \n",
            "1170   118  1.254914  0.350287  0.302488  0.693114 -0.371470 -1.070256   \n",
            "1209   529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n",
            "1248   529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n",
            "1287   574  1.257719  0.364739  0.306923  0.690638 -0.357792 -1.067481   \n",
            "1326     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
            "1365   472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
            "1404   118  1.254914  0.350287  0.302488  0.693114 -0.371470 -1.070256   \n",
            "1443   118  1.254914  0.350287  0.302488  0.693114 -0.371470 -1.070256   \n",
            "1482   574  1.257719  0.364739  0.306923  0.690638 -0.357792 -1.067481   \n",
            "1521   529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n",
            "\n",
            "            V7        V8        V9  ...       V21       V22       V23  \\\n",
            "0     0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
            "39   -0.031849  0.117620  0.017665  ... -0.037709  0.095701 -0.048198   \n",
            "78    1.061148 -0.410972 -0.179130  ...  0.003559  0.561240 -0.199287   \n",
            "117  -0.336555  0.670704  0.071670  ...  0.315868  0.847565  0.148877   \n",
            "156   0.656183  0.009755 -0.635963  ... -0.147934 -0.420046  0.061424   \n",
            "195  -0.061695 -0.125223  0.984938  ...  0.146077  0.481119 -0.140019   \n",
            "234  -0.428879  0.284565  0.406555  ...  0.162123  0.454364 -0.263576   \n",
            "273   0.736469 -0.327992 -0.555549  ...  0.009613  0.315739  0.054210   \n",
            "312  -0.279252 -0.205606 -0.647806  ...  0.071144  0.210635 -0.356278   \n",
            "351  -0.649554  0.534756  0.886183  ... -0.074659  0.397405  0.199030   \n",
            "390   0.238933  0.163402 -0.584981  ...  0.062165 -0.016076 -0.236314   \n",
            "429   1.315730 -0.010903 -0.360987  ...  0.154089  0.339031  0.372442   \n",
            "468  -0.086554  0.157807  1.677621  ...  0.361562 -0.173006  1.280446   \n",
            "507   0.531504 -0.081955 -0.522527  ... -0.070069  0.556788  0.217681   \n",
            "546  -1.057919  0.009986 -0.460486  ... -0.142455  0.042134 -0.125057   \n",
            "585  -0.793082  0.146590  1.676342  ...  0.220590  0.901360 -0.276484   \n",
            "624   0.055026  0.045165 -0.350573  ...  0.188378  0.487631 -0.147081   \n",
            "663   0.179124  0.616512 -0.151023  ...  0.008982 -0.075797 -0.057756   \n",
            "702   0.143747 -0.111374  0.790809  ...  0.081582  0.534693 -0.159644   \n",
            "741  -0.230310 -0.012302  0.123302  ...  0.171834  0.659725 -0.064483   \n",
            "780   0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
            "819  -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
            "858  -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836   \n",
            "897  -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836   \n",
            "936  -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
            "975   0.086781 -0.202836  0.035154  ... -0.287592 -0.832682  0.128083   \n",
            "1014  0.094272 -0.210300  0.014455  ... -0.286856 -0.820658  0.127663   \n",
            "1053  0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
            "1092  0.086781 -0.202836  0.035154  ... -0.287592 -0.832682  0.128083   \n",
            "1131  0.094272 -0.210300  0.014455  ... -0.286856 -0.820658  0.127663   \n",
            "1170  0.086781 -0.202836  0.035154  ... -0.287592 -0.832682  0.128083   \n",
            "1209 -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836   \n",
            "1248 -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836   \n",
            "1287  0.094272 -0.210300  0.014455  ... -0.286856 -0.820658  0.127663   \n",
            "1326 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
            "1365  0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
            "1404  0.086781 -0.202836  0.035154  ... -0.287592 -0.832682  0.128083   \n",
            "1443  0.086781 -0.202836  0.035154  ... -0.287592 -0.832682  0.128083   \n",
            "1482  0.094272 -0.210300  0.014455  ... -0.286856 -0.820658  0.127663   \n",
            "1521 -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836   \n",
            "\n",
            "           V24       V25       V26       V27       V28  Amount  Class  \n",
            "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "39    0.232115  0.606201 -0.342097  0.036770  0.007480    6.54      0  \n",
            "78    0.001387 -0.179530 -0.374116  0.071641 -0.175510    9.79      0  \n",
            "117   0.549791 -0.585131  0.325841 -0.068871  0.059713   50.00      0  \n",
            "156   0.520997 -0.238845  0.030135  0.140481  0.101163   14.98      0  \n",
            "195   0.538261  0.710720 -0.621382  0.036867  0.010963    8.80      0  \n",
            "234   0.144388  0.483056  0.222374  0.031597  0.056036  184.31      0  \n",
            "273   0.294232  0.003877 -0.314159 -0.099512  0.122697    1.00      0  \n",
            "312  -0.954151  0.963445  0.019195 -0.016289 -0.006384   34.00      0  \n",
            "351  -1.386013 -0.141955 -0.984011  0.274079 -0.019784   55.45      0  \n",
            "390  -0.082802  0.357494 -0.110530  0.080796  0.113264    1.00      0  \n",
            "429   0.172197 -0.230872 -0.363260 -0.067174 -0.066832  222.50      0  \n",
            "468   0.012697  0.760879 -0.828147 -0.298700 -0.061615  456.71      0  \n",
            "507   0.100721 -0.332479  0.252526  0.138865 -0.085152   29.18      0  \n",
            "546  -0.403785  0.212596  0.619155  0.035518  0.041399   72.00      0  \n",
            "585  -1.249997  0.646935 -0.440130  0.127178  0.027224    8.49      0  \n",
            "624   0.036691  0.565457 -0.275489  0.023386  0.019021   59.88      0  \n",
            "663  -0.388366 -0.296798  0.774677 -0.418797 -0.184978    3.00      0  \n",
            "702   0.296812  0.855793 -0.553063  0.054274  0.001410    1.00      0  \n",
            "741   0.125329  0.506081 -0.270854  0.069604  0.030001    1.00      0  \n",
            "780  -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
            "819   0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
            "858  -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50      1  \n",
            "897  -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50      1  \n",
            "936  -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
            "975   0.339427  0.215944  0.094704 -0.023354  0.030892    2.69      1  \n",
            "1014  0.343128  0.221120  0.094391 -0.022189  0.030944    1.29      1  \n",
            "1053 -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
            "1092  0.339427  0.215944  0.094704 -0.023354  0.030892    2.69      1  \n",
            "1131  0.343128  0.221120  0.094391 -0.022189  0.030944    1.29      1  \n",
            "1170  0.339427  0.215944  0.094704 -0.023354  0.030892    2.69      1  \n",
            "1209 -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50      1  \n",
            "1248 -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50      1  \n",
            "1287  0.343128  0.221120  0.094391 -0.022189  0.030944    1.29      1  \n",
            "1326 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
            "1365 -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
            "1404  0.339427  0.215944  0.094704 -0.023354  0.030892    2.69      1  \n",
            "1443  0.339427  0.215944  0.094704 -0.023354  0.030892    2.69      1  \n",
            "1482  0.343128  0.221120  0.094391 -0.022189  0.030944    1.29      1  \n",
            "1521 -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50      1  \n",
            "\n",
            "[40 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import math\n",
        "# Calculate the number of rows in the dataset\n",
        "n = len(cc_balanced)\n",
        "\n",
        "# Set the sampling interval \"k\" as the square root of the number of rows in the dataset\n",
        "k = int(math.sqrt(n))\n",
        "\n",
        "# Select every \"k\" row starting from a random index in the dataset\n",
        "cc_systematic_sample = cc_balanced.iloc[::k]\n",
        "\n",
        "# Print the first few rows of the sample\n",
        "print(cc_systematic_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "WrftrTwI5i8D",
        "outputId": "92f4da59-64f7-4b16-99a3-0c4302e70aad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression accuracy: 0.9166666666666666\n",
            "Decision Tree accuracy: 0.8333333333333334\n",
            "SVC accuracy: 0.9166666666666666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jatin\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest accuracy: 1.0\n",
            "Naive bayes Classifier accuracy: 0.8333333333333334\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random_Sampling</th>\n",
              "      <th>Systematic_Sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.895833</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Random_Sampling  Systematic_Sampling\n",
              "Logistic Regression         0.895833             0.916667\n",
              "Decision Tree               0.989583             0.833333\n",
              "SVC                         0.927083             0.916667\n",
              "Random forest               1.000000             1.000000\n",
              "Naive Bayes                 0.739583             0.833333"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Now we will aplly 5 different models to our systematic sample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "x_systematic= cc_systematic_sample.drop(columns=['Class'])\n",
        "y_systematic = cc_systematic_sample['Class']\n",
        "x_systematic_train, x_systematic_test,y_systematic_train, y_systematic_test = train_test_split(x_systematic,y_systematic, random_state=121, \n",
        "                                   test_size=0.3, \n",
        "                                   shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# Train and evaluate the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "     \"SVC\" : svm.SVC(kernel='linear', C = 1.0) \n",
        "    ,\n",
        "    \"Random Forest\": RandomForestClassifier() ,\n",
        "    \"Naive bayes Classifier\":GaussianNB()\n",
        "    \n",
        "}\n",
        "acc_l2=[]\n",
        "for name, model in models.items():\n",
        "    model.fit(x_systematic_train,y_systematic_train)\n",
        "    y_pred = model.predict(x_systematic_test)\n",
        "    acc = accuracy_score(y_systematic_test, y_pred)\n",
        "    print(f\"{name} accuracy: {acc}\")\n",
        "    acc_l2.append(acc)\n",
        "acc_m['Systematic_Sampling']=acc_l2\n",
        "acc_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "RXnSK2ZtpM15"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "\n",
        "\n",
        "# Separate the feature matrix X and the target variable y\n",
        "X = cc_balanced.drop(columns=['Class'])\n",
        "y = cc_balanced['Class']\n",
        "\n",
        "# Determine the number of strata (in this case, we use a binary target variable, so there are two strata)\n",
        "num_strata = 2\n",
        "\n",
        "# Initialize an empty list to store the stratified samples\n",
        "samples = []\n",
        "\n",
        "# Loop over each stratum\n",
        "for i in range(num_strata):\n",
        "    # Subset the data to include only the observations in the current stratum\n",
        "    stratum_data = cc_balanced[cc_balanced['Class'] ==i]\n",
        "    \n",
        "    # Calculate the sample size for the current stratum\n",
        "    stratum_size = len(stratum_data)\n",
        "    population_size=len(cc_balanced)\n",
        "    p=0.5\n",
        "    error=0.05\n",
        "    z_score = 1.96  # for a 95% confidence level\n",
        "    p = stratum_size / population_size\n",
        "    q = 1 - p\n",
        "    n = int((z_score**2 * p * q * population_size) / ((z_score**2 * p * q) + (error**2 * (population_size-1))))\n",
        "    \n",
        "    \n",
        "    # If the calculated sample size for the current stratum is greater than the number of observations in the stratum, set the sample size to the number of observations\n",
        "    if n > stratum_size:\n",
        "        n = stratum_size\n",
        "    \n",
        "    # Randomly select observations from the current stratum to include in the sample\n",
        "    sample_indices = np.random.choice(stratum_data.index, size=n, replace=False)\n",
        "    stratum_sample = stratum_data.loc[sample_indices]\n",
        "    \n",
        "    # Add the current stratum sample to the list of stratified samples\n",
        "    samples.append(stratum_sample)\n",
        "\n",
        "# Combine the stratified samples into a single DataFrame\n",
        "stratified_sample = pd.concat(samples)\n",
        "\n",
        "# Write the stratified sample to a new CSV file\n",
        "stratified_sample.to_csv('stratified_dataset.csv', index=False)\n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "98K4iM197bQi",
        "outputId": "b68b08a1-b62d-494b-b0bf-a6e594dabd4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression accuracy: 0.9243243243243243\n",
            "Decision Tree accuracy: 0.9837837837837838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jatin\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC accuracy: 0.9243243243243243\n",
            "Random Forest accuracy: 1.0\n",
            "Naive bayes Classifier accuracy: 0.6756756756756757\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random_Sampling</th>\n",
              "      <th>Systematic_Sampling</th>\n",
              "      <th>Stratified_Sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.895833</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.924324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.983784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.924324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.675676</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Random_Sampling  Systematic_Sampling  Stratified_Sampling\n",
              "Logistic Regression         0.895833             0.916667             0.924324\n",
              "Decision Tree               0.989583             0.833333             0.983784\n",
              "SVC                         0.927083             0.916667             0.924324\n",
              "Random forest               1.000000             1.000000             1.000000\n",
              "Naive Bayes                 0.739583             0.833333             0.675676"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Now we will aplly 5 different models to our stratified sample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "x_stratified= stratified_sample.drop(columns=['Class'])\n",
        "y_stratified = stratified_sample['Class']\n",
        "x_stratified_train, x_stratified_test,y_stratified_train, y_stratified_test = train_test_split(x_stratified,y_stratified, random_state=121, \n",
        "                                   test_size=0.3, \n",
        "                                   shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# Train and evaluate the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "     \"SVC\" : svm.SVC(kernel='linear', C = 1.0) \n",
        "    ,\n",
        "    \"Random Forest\": RandomForestClassifier() ,\n",
        "    \"Naive bayes Classifier\":GaussianNB()\n",
        "    \n",
        "}\n",
        "acc_l3=[]\n",
        "for name, model in models.items():\n",
        "    model.fit(x_stratified_train,y_stratified_train)\n",
        "    y_pred = model.predict(x_stratified_test)\n",
        "    acc = accuracy_score(y_stratified_test, y_pred)\n",
        "    print(f\"{name} accuracy: {acc}\")\n",
        "    acc_l3.append(acc)\n",
        "acc_m['Stratified_Sampling']=acc_l3\n",
        "acc_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tdo6-EFW9Oq",
        "outputId": "6ab4d2cd-faad-4e02-e239-7314e660f622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Time        V1        V2        V3        V4        V5        V6  \\\n",
            "1361   438 -1.741253  1.311033 -0.227532  2.424078  0.091866 -1.209753   \n",
            "511    377  1.166919  0.027049  0.513875  0.860965 -0.519452 -0.681147   \n",
            "9        9 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761   \n",
            "393    284 -0.810756  0.654499  2.217257  0.104341 -0.286801  0.117833   \n",
            "471    346  1.077079  0.284980  0.007731  1.657073  0.052020  0.446389   \n",
            "...    ...       ...       ...       ...       ...       ...       ...   \n",
            "829    455 -2.187620  0.173822  0.020197  2.855292  0.670941 -0.618595   \n",
            "530    394  1.293053  0.457969 -1.940450  0.173149  2.609570  3.014117   \n",
            "1363   436 -1.267646 -1.854803  1.979809  1.039432  1.824096  0.219522   \n",
            "795    457 -1.218835  1.465853 -1.022788  2.984967 -0.471837 -1.316572   \n",
            "1370   272 -0.266159  0.499202  0.889096  0.137925  0.871590 -0.139348   \n",
            "\n",
            "            V7        V8        V9  ...       V21       V22       V23  \\\n",
            "1361 -1.128082  0.752988 -1.686021  ...  0.331240  0.095480 -0.379720   \n",
            "511   0.074992 -0.187776  0.345399  ... -0.202750 -0.441391 -0.025782   \n",
            "9     0.651583  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794   \n",
            "393   0.287552 -0.736461  0.699092  ...  0.938194  0.571651 -0.101609   \n",
            "471  -0.407036  0.355704  0.626039  ... -0.174337 -0.174161 -0.153375   \n",
            "...        ...       ...       ...  ...       ...       ...       ...   \n",
            "829  -2.366584  1.150444 -1.279218  ...  0.479338  0.456901 -0.160133   \n",
            "530  -0.269415  0.754420 -0.221009  ... -0.121126 -0.427753 -0.159336   \n",
            "1363 -1.615570  0.565198  0.750863  ...  0.262597  0.738804  0.259619   \n",
            "795  -1.731372  0.901015 -1.917248  ...  0.270959 -0.275663 -0.283628   \n",
            "1370  0.493922  0.039088 -0.129516  ... -0.062592 -0.156992  0.012320   \n",
            "\n",
            "           V24       V25       V26       V27       V28     Amount  Class  \n",
            "1361  0.347088  0.187495 -0.082741  0.110334 -0.136053   0.412511      1  \n",
            "511   0.452607  0.467223  0.262577 -0.023834  0.020521  40.830000      0  \n",
            "9    -0.385050 -0.069733  0.094199  0.246219  0.083076   3.680000      0  \n",
            "393   0.363928 -0.170947 -0.471524  0.058958 -0.079157  30.300000      0  \n",
            "471  -0.466331  0.611001 -0.252871  0.090375  0.054820  10.990000      0  \n",
            "...        ...       ...       ...       ...       ...        ...    ...  \n",
            "829  -0.150506 -0.060969  0.450985  0.106909 -0.154384   0.599723      1  \n",
            "530   0.857135  0.850055 -0.311685  0.037536  0.050618   1.000000      0  \n",
            "1363 -0.587724 -0.121329  0.688495 -0.101823 -0.125594   1.767910      1  \n",
            "795   0.327221  0.098608  0.152281  0.174366 -0.089916   0.395097      1  \n",
            "1370 -0.770730 -0.785382 -0.104071  0.117739  0.109466   0.993391      1  \n",
            "\n",
            "[384 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "X = cc.drop(columns=['Class'])\n",
        "y = cc['Class']\n",
        "smote = SMOTE()\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_smote, y_smote = smote.fit_resample(x, y)\n",
        "smote_random = pd.concat((pd.DataFrame(x_smote),pd.DataFrame(y_smote)),axis=1)\n",
        "np.random.seed(0)\n",
        "\n",
        "sample_size=int((pow(1.96,2)*0.5*0.5)/0.0025)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "smote_r_sample = smote_random.sample(n=sample_size, random_state=0)\n",
        "print(smote_r_sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "Ds7Ku4daatrA",
        "outputId": "c3669932-1224-4734-e71f-b2293b2d6d47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression accuracy: 0.9243243243243243\n",
            "Decision Tree accuracy: 0.9891891891891892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jatin\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC accuracy: 0.9243243243243243\n",
            "Random Forest accuracy: 1.0\n",
            "Naive bayes Classifier accuracy: 0.6756756756756757\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random_Sampling</th>\n",
              "      <th>Systematic_Sampling</th>\n",
              "      <th>Stratified_Sampling</th>\n",
              "      <th>SMOTE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.895833</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.924324</td>\n",
              "      <td>0.924324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.983784</td>\n",
              "      <td>0.989189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.924324</td>\n",
              "      <td>0.924324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>0.675676</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Random_Sampling  Systematic_Sampling  \\\n",
              "Logistic Regression         0.895833             0.916667   \n",
              "Decision Tree               0.989583             0.833333   \n",
              "SVC                         0.927083             0.916667   \n",
              "Random forest               1.000000             1.000000   \n",
              "Naive Bayes                 0.739583             0.833333   \n",
              "\n",
              "                     Stratified_Sampling     SMOTE  \n",
              "Logistic Regression             0.924324  0.924324  \n",
              "Decision Tree                   0.983784  0.989189  \n",
              "SVC                             0.924324  0.924324  \n",
              "Random forest                   1.000000  1.000000  \n",
              "Naive Bayes                     0.675676  0.675676  "
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "x_smote= smote_r_sample.drop(columns=['Class'])\n",
        "y_smote = smote_r_sample['Class']\n",
        "x_smote_train, x_smote_test,y_smote_train, y_smote_test = train_test_split(x_smote,y_smote, random_state=121, \n",
        "                                   test_size=0.3, \n",
        "                                   shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# Train and evaluate the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "     \"SVC\" : svm.SVC(kernel='linear', C = 1.0) \n",
        "    ,\n",
        "    \"Random Forest\": RandomForestClassifier() ,\n",
        "    \"Naive bayes Classifier\":GaussianNB()\n",
        "    \n",
        "}\n",
        "acc_l5=[]\n",
        "for name, model in models.items():\n",
        "    model.fit(x_stratified_train,y_stratified_train)\n",
        "    y_pred = model.predict(x_stratified_test)\n",
        "    acc = accuracy_score(y_stratified_test, y_pred)\n",
        "    print(f\"{name} accuracy: {acc}\")\n",
        "    acc_l5.append(acc)\n",
        "acc_m['SMOTE']=acc_l5\n",
        "acc_m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Convinience Sampling\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "sample_size=600\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "con_sample = cc_balanced.sample(n=sample_size, random_state=91)\n",
        "\n",
        "len(con_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jatin\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression accuracy: 0.8944444444444445\n",
            "Decision Tree accuracy: 0.9666666666666667\n",
            "SVC accuracy: 0.9\n",
            "Random Forest accuracy: 1.0\n",
            "Naive bayes Classifier accuracy: 0.8444444444444444\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random_Sampling</th>\n",
              "      <th>Systematic_Sampling</th>\n",
              "      <th>Stratified_Sampling</th>\n",
              "      <th>SMOTE</th>\n",
              "      <th>Convinience_Sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.895833</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.924324</td>\n",
              "      <td>0.924324</td>\n",
              "      <td>0.894444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.983784</td>\n",
              "      <td>0.989189</td>\n",
              "      <td>0.966667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.924324</td>\n",
              "      <td>0.924324</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>0.844444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Random_Sampling  Systematic_Sampling  \\\n",
              "Logistic Regression         0.895833             0.916667   \n",
              "Decision Tree               0.989583             0.833333   \n",
              "SVC                         0.927083             0.916667   \n",
              "Random forest               1.000000             1.000000   \n",
              "Naive Bayes                 0.739583             0.833333   \n",
              "\n",
              "                     Stratified_Sampling     SMOTE  Convinience_Sampling  \n",
              "Logistic Regression             0.924324  0.924324              0.894444  \n",
              "Decision Tree                   0.983784  0.989189              0.966667  \n",
              "SVC                             0.924324  0.924324              0.900000  \n",
              "Random forest                   1.000000  1.000000              1.000000  \n",
              "Naive Bayes                     0.675676  0.675676              0.844444  "
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "x_con= con_sample.drop(columns=['Class'])\n",
        "y_con = con_sample['Class']\n",
        "x_con_train, x_con_test,y_con_train, y_con_test = train_test_split(x_con,y_con, random_state=121, \n",
        "                                   test_size=0.3, \n",
        "                                   shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# Train and evaluate the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "     \"SVC\" : svm.SVC(kernel='linear', C = 1.0) \n",
        "    ,\n",
        "    \"Random Forest\": RandomForestClassifier() ,\n",
        "    \"Naive bayes Classifier\":GaussianNB()\n",
        "    \n",
        "}\n",
        "acc_l4=[]\n",
        "for name, model in models.items():\n",
        "    model.fit(x_con_train,y_con_train)\n",
        "    y_pred = model.predict(x_con_test)\n",
        "    acc = accuracy_score(y_con_test, y_pred)\n",
        "    print(f\"{name} accuracy: {acc}\")\n",
        "    acc_l4.append(acc)\n",
        "acc_m['Convinience_Sampling']=acc_l4\n",
        "acc_m"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "32cdeed936141e1f2e77a14e89d312a72fc6e9940eb399bd0c10e89bc21c5645"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
